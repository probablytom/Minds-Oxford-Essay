@article{Sloman1984TheMinds,
    title = {{The Structure of the Space of Possible Minds}},
    year = {1984},
    author = {Sloman, Aaron},
    pages = {35--42}
}

@article{corrigibility,
author = {Soares, Nate and Fallenstein, Benja and Yudkowsky, Eliezer and Armstrong, Stuart},
journal = {AAAI Workshop on AI and Ethics},
number = {2014},
pages = {74--82},
title = {{Corrigibility}},
year = {2015}
}

@article{concrete_problems,
  author    = {Dario Amodei and
               Chris Olah and
               Jacob Steinhardt and
               Paul Christiano and
               John Schulman and
               Dan Man{\'{e}}},
  title     = {Concrete Problems in {AI} Safety},
  journal   = {CoRR},
  volume    = {abs/1606.06565},
  year      = {2016},
}

@article{bostrom2003ethical,
  title={Ethical issues in advanced artificial intelligence},
  author={Bostrom, Nick},
  journal={Science Fiction and Philosophy: From Time Travel to Superintelligence},
  pages={277--284},
  year={2003}
}

@article{basic_ai_drives,
abstract = {One might imagine that AI systems with harmless goals will be harmless. This paper instead shows that intelligent systems will need to be carefully designed to prevent them from behaving in harmful ways. We identify a number of " drives " that will appear in sufficiently advanced AI systems of any design. We call them drives because they are tendencies which will be present unless explicitly coun-teracted. We start by showing that goal-seeking systems will have drives to model their own operation and to improve themselves. We then show that self-improving systems will be driven to clarify their goals and represent them as economic utility functions. They will also strive for their actions to approximate rational economic behavior. This will lead almost all systems to protect their utility functions from modification and their utility measurement systems from corruption. We also dis-cuss some exceptional systems which will want to modify their utility functions. We next discuss the drive toward self-protection which causes systems try to pre-vent themselves from being harmed. Finally we examine drives toward the acqui-sition of resources and toward their efficient utilization. We end with a discussion of how to incorporate these insights in designing intelligent technology which will lead to a positive future for humanity.},
author = {Omohundro, Stephen M},
keywords = {Artificial Intelligence,Cognitive Drives,Rational Economic Behavior,Self-Improving Systems,Utility Engineering},
title = {{The Basic AI Drives}}
}

@article{Marsh1994FormalisingConcept,
    title = {{Formalising Trust as a Computational Concept}},
    year = {1994},
    journal = {Computing},
    author = {Marsh, Stephen Paul},
    number = {April},
    pages = {184},
    volume = {Doctor of},
    isbn = {CSM-133},
    doi = {10.2165/00128413-199409230-00010}
}

@inproceedings{eigentrust,
  title={The eigentrust algorithm for reputation management in p2p networks},
  author={Kamvar, Sepandar D and Schlosser, Mario T and Garcia-Molina, Hector},
  booktitle={Proceedings of the 12th international conference on World Wide Web},
  pages={640--651},
  year={2003},
  organization={ACM}
}

@article{CastelfranchiSocialApproach,
    title = {{Social Trust: A Cognitive Approach}},
    author = {Castelfranchi, Cristiano and Falcone, Rino},
    year = {2001}
}

@article{luhmann2000familiarity,
  title={Familiarity, confidence, trust: Problems and alternatives},
  author={Luhmann, Niklas},
  year={2000}
}

@article{deutsch1962cooperation,
  title={Cooperation and trust: Some theoretical notes.},
  author={Deutsch, Morton},
  year={1962},
  publisher={Univer. Nebraska Press}
}

